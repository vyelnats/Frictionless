Whether experimentalists or theoreticians, all physicists deal with large quantities of data, often from external sources. Finding and using this data is not always straightforward, however, and can involve a degree of “friction,” such as poor formatting, illogical structures, and incompleteness, in turn leading to speed bumps in data sharing, implementation and publication.  The Frictionless Data project ([Frictionless Data | Frictionless Data](https://frictionlessdata.io/)) at the Open Knowledge Foundation ( [http://okfn.org](http://okfn.org/) ) is creating open source tools for handling messy data in order to promote research reproducibility. Built in Python, Frictionless is a set of software, tools and specifications (https://frictionlessdata.io/software/ ; https://frictionlessdata.io/specs/) with a focus on improving data and metadata interoperability.  As a Frictionless Reproducible Research Fellow ([Welcome to the Frictionless Data for Reproducible Research Fellows Programme!](https://fellows.frictionlessdata.io/)), I’ve not only been working with these tools as part of the prototyping process, but also learning about the importance of reproducibility, and thinking about how this could be implemented in my own field of molecular spectroscopy ([Calibration-Free Gas Quantification through Wavelength Modulation Spectroscopy in the Millimeter-Wave/Terahertz Range | IEEE Conference Publication | IEEE Xplore](https://ieeexplore.ieee.org/document/9567606))  - heavily reliant on open source spectral databases and information consolidation for molecular identification. This talk will centre on common data lifecycle pain points in physics, circumventing some of them using Frictionless tools, and the overarching importance of reproducibility as an end goal.  Some technical background behind the Frictionless Python libraries will be discussed, but mainly I’ll focus on application using spectroscopic data, for example, how to package spectroscopic data with metadata and validate it. This talk is appropriate for those coming from a natural science background as well as a data background… basically anyone interested in exposure to new ways of wrangling messy research data in Python! 
